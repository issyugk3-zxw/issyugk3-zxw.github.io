---
title: Some-Definitions
createTime: 2025/03/25 13:23:46
permalink: /ML/strwr24u/
---
## Bayes's Theorem
Bayesian takes probability theory to quantify the uncertainty. Bayes's theorem integrate observations and prior to posterior:
$$ p(w | D )=\frac{p(D|w)p(w)}{p(D)} = \frac{p(D|w)p(w)}{\int p(D|w)dw} $$

In the above equation, $p(w | D )$ is the posterior. $p(D|w)$ and $p(w)$ are likelihood and prior, respectively. We can get the denominator by integrating $w$ over the marginal function.

The denominator in Bayes' theorem is the normalization factor that ensures the posterior is a valid probability distribution. Therefore we can express the Bayes's Theorem as : $\text{postrior} \propto \text{likelihood} \times \text{prior}$, and all the components can be seen as a function of $w$.

## Advantages & Disadvantages
Likelihood usually comes from dataset. So Bayes method must choose a prior distribution first. There are good things about having a prior distribution, like it prevents the result ending to some extremes. But also there are arguements critisize that sometimes chosen prior is just for simplifying computation without reflecting any truth. In other hands, computing denominator is also very difficult. Methods are proposed to solve these problems.
